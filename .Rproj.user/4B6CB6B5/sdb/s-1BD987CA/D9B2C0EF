{
    "collab_server" : "",
    "contents" : "---\ntitle: \"ISIP Analysis\"\nauthor: \"Michael P. McDonald\"\ndate: \"2/14/2017\"\noutput:\nhtml_document:\ncode_folding: hide\ntheme: paper\ntoc: yes\ntoc_depth: 3\ntoc_float: yes\n---\n\n## Introduction\n\nData were collected January - February, 2017, under the specifications of the CRATER IRB (get #).\n\n\n```{r setup, include=FALSE}\nlibrary(RWiener)\nlibrary(rtdists)\nlibrary(pander)\npanderOptions(\"digits\", 3)\nlibrary(broom)\nlibrary(knitr)\nlibrary(psych)\nlibrary(forcats)\nlibrary(tidyverse)\nsource('R/DDMfunctions.R')\nsource('R/IATfunctions.R')\nsource('R/summarySE.R')\nsource('R/bootstrapfunctions.R')\n\n# read in data, filter out test subjects (>= 900)\n\nload('extdata/ISIP_raw.Rdata')\n\n# Define excluded subjects.  Subject exclusion rationale is included in the subject roster.\n# Lab testing IDs are >= 900\n\nexcludedSubjects <- c(1, 219, 152, 153, 189)\n\n```\n\n\n```{r iats}\nageIAT$experiment <- \"ageIAT\"\nfiIAT$experiment <- \"flowerIAT\"\ntbl_iat <- rbind(ageIAT, fiIAT) %>% \n  select(c(6:15, 20)) %>%\n  filter(!(subject %in% excludedSubjects))\n\n# Convert latencies from milliseconds to seconds\ntbl_iat$latency <- tbl_iat$latency/1000\n\n\n```\n\n```{r pairings}\n\n## Pairing Assignment\n# \n# Pairing is defined by which experimental block type is represented.\n# \n# 1. practice good vs bad (20 trials)\n# 2. practice white vs black (20 trials)\n# 3. practice white/good vs black/bad (20 trials)\n# 4. test white/good vs black/bad (40 trials)\n# 5. switch practice (40 trials)\n# 6. practice white/bad vs black/good (20 trials)\n# 7. test white/bad vs black/good (40 trials)\n\ntbl_iat <- tbl_iat %>%\n  mutate(pairing = fct_recode(blockcode,\n                              \"1\" = \"attributepractice\",\n                              '2' = \"targetcompatiblepractice\",\n                              '3' = \"compatibletest1\",\n                              '4' = \"compatibletest2\",\n                              '5' = \"targetincompatiblepractice\",\n                              '6' = \"incompatibletest1\",\n                              '7' = \"incompatibletest2\")\n  )\n                              \n```\n\n```{r iatCalculations, message=FALSE}\ntbl_D_calc_statistics_long <- tbl_iat %>%\n  select(experiment, subject, pairing, latency) %>%\n  group_by(subject, pairing, experiment) %>%\n  summarize(mean_latency = mean(latency),\n            sd_latency = sd(latency),\n            n_trials = n()) %>%\n  filter(!(subject %in% excludedSubjects) & !is.na(pairing) & !is.na(mean_latency) & !is.na(sd_latency) & !is.na(n_trials))\n\n# should probably do some test_that type of things to verify integrity of data, e.g.\n# based on number of trials.\n\n# Separately spread statistics into wide form and rename the variables appropriately\n# (there are better ways to do this, but it's not worth rewriting)\n\n\nmoo <- tbl_D_calc_statistics_long %>% \n  gather(variable, value, mean_latency, sd_latency, n_trials) %>%\n  unite(temp, pairing, experiment) %>%\n  spread(temp, )\n\n\ntemp1 <- tbl_D_calc_statistics_long %>% select(subject, pairing, experiment, mean_latency) %>% spread(pairing, mean_latency)\n\n\ntemp2 <- print(tbl_D_calc_statistics_long %>% select(subject, pairing, experiment, sd_latency) %>% spread(pairing, sd_latency))\ntemp3 <- tbl_D_calc_statistics_long %>% select(subject, pairing, experiment, n_trials) %>% spread(pairing, n_trials)\nnames(temp1) <- c(\"subject\", paste(\"lat\", 1:7, sep=\"\"))\nnames(temp2) <- c(\"subject\", paste(\"sd\", 1:7, sep=\"\"))\nnames(temp3) <- c(\"subject\", paste(\"n\", 1:7, sep=\"\"))\n\n\n\n# Join temporary tables into one wide-form table\ntbl_D_calc_statistics <- temp1 %>% left_join(temp2) %>% left_join(temp3)\n\n# Remove temporary tables\nrm(list=c(paste(\"temp\", 1:3, sep=\"\")))\n\n# # IAT calculations # #\n\ntbl_D_calc_statistics$dPractice <- with(tbl_D_calc_statistics, dScore(lat6, lat3, sd6, sd3, n6, n3))\ntbl_D_calc_statistics$dTest <- with(tbl_D_calc_statistics, dScore(lat7, lat4, sd7, sd4, n7, n4))\ntbl_D_calc_statistics$dAll <- (.5*tbl_D_calc_statistics$dPractice+.5*tbl_D_calc_statistics$dTest)\n\n\n# Create a variable that indicates whether or not a dataset is complete\ntbl_D_calc_statistics$complete <- !is.na(rowSums(tbl_D_calc_statistics))\n\ntbl_D_calc_statistics$meanLat <- with(tbl_D_calc_statistics, (lat3+lat4+lat6+lat7)/4)\n```\n\n### Inclusion criteria \n\nFor purposes of inclusion in this analysis, subjects must:\n\n*  Have fewer than 10% trials with a response time under 300ms\n*  Have an error rate of less than 40% in ALL blocks\n\n```{r exclusion}\n# # # Perform data reduction based on inclusion/drop criteria\n\n# # Set criteria here\n\ncriterion_under300 <- .1  # Allowed overall proportion of responses under 300ms\n\ncriterion_blockErrorRate <- .4  # Allowed proportional error rate in ANY BLOCK\n\n# Create flags for ANY paired block with > specified error rate\n# Flag variables are TRUE if a subject should be EXCLUDED based on the criterion\n\nflagError40 <- tbl_iat %>%\n  select(subject, pairing, correct) %>%\n  group_by(subject, pairing) %>%\n  summarize(error_rate = mean(1-correct)) %>%\n  group_by(subject) %>%\n  summarize(flag = max(error_rate) >= criterion_blockErrorRate)\n\nmessage_errorRate <- paste(\"Subjects exceeding block error rate of \",\n                           criterion_blockErrorRate, \": \",\n                           sum(flagError40$flag), \" of \",\n                           length(flagError40$subject), \", approximately \",\n                           round(mean(flagError40$flag),2)*100, \"%\", sep=\"\")\n\n# Create flags for total % trials under 300ms in all paired blocks\n\nflagUnder300 <- tbl_iat %>%\n  select(subject, pairing, latency) %>%\n  filter(pairing %in% c(\"3\",\"4\",\"6\",\"7\")) %>% # only examine in paired blocks\n  group_by(subject) %>%\n  summarize(meanUnder300 = mean(latency <= .3), # returns proportion under 300ms\n            flag = mean(latency <= .3) > criterion_under300)\n\nsubjectsFlaggedUnder300 <- flagUnder300 %>% filter(flag) %>% select(subject)\n\nmessage_under300 <- paste(\"Subjects with more than \",\n                          criterion_under300*100, \"% of trials under 300ms: \",\n                          sum(flagUnder300$flag), \" of \",\n                          length(flagUnder300$subject), \", approximately \",\n                          round(mean(flagUnder300$flag),2)*100, \"%\", sep=\"\")\n\n# Perform filtration\n\ntbl_D_calc_statistics <- tbl_D_calc_statistics %>%\n  filter(complete) %>%\n  filter(subject %in% unique(flagUnder300[flagUnder300$flag==FALSE,]$'subject')) %>%\n  filter(subject %in% unique(flagError40[flagError40$flag==FALSE,]$'subject'))\n\nmessage_totalSubjects <- paste(\"\\nTotal subjects included in analysis: \",\n                               length(tbl_D_calc_statistics$subject), sep=\"\")\n\n# # # Save out data for downstream use\n\n# Write out a brief IAT data table for later use\n\ntbl_D_brief <- tbl_D_calc_statistics %>%\n  filter(complete) %>%\n  select(subject, meanLat, dPractice, dTest, dAll)\n\nwrite.csv(tbl_D_brief, \"data/IATbrief.csv\", row.names = FALSE)\n\n# Save data file containing IAT results along with all blockwise statistics\nwrite.csv(tbl_D_calc_statistics, \"data/iatVerboseOLPS.csv\")\n\n# Save list of all subjects with complete IAT data\ntbl_completeSubjects <- tbl_D_calc_statistics %>% select(subject)\nwrite.csv(tbl_completeSubjects, \"data/includedSubjects.csv\", row.names=FALSE)\n\n# Save tbl_iat\nwrite.csv(tbl_iat, \"data/tbl_iat.csv\", row.names=FALSE)\n```\nExclusion summary:\n\n*  `r message_totalSubjects`\n*  `r message_under300`\n*  `r message_errorRate`\n\n## IAT Summary\n```{r IATsummary}\niatSummaries <- tbl_D_calc_statistics %>%\n  select(subject, dPractice, dTest, dAll) %>%\n  gather(variable, value, dPractice:dAll) %>%\n  group_by(variable) %>%\n  do(bootSummary(.$value))\n\ntbl_D_calc_statistics %>%\n  select(subject, dPractice, dTest, dAll) %>%\n  gather(variable, value, dPractice:dAll) %>%\n  ggplot(., aes(value)) +\n  geom_histogram() +\n  xlab(\"Block D calculation (using only practice, only test, or all blocks)\") +\n  ylab(\"Density\") +\n  ggtitle(\"D score distributions by Block Calculation\") +\n  facet_grid(. ~variable)\n\n```\n\n\n## Probabilistic Stimulus Selection (PSS) task\n\n```{r scorePSS, results='asis'}\n# Need to return:\n# 1. Choose A accuracy\n# 2. Avoid B accuracy\n# 3. Overall accuracy\n# 4. Number of training trials\n\nchooseAtrials <- c(\"AC\", \"CA\", \"AD\", \"DA\", \"AE\", \"EA\", \"AF\", \"FA\")\navoidBtrials <- c(\"BC\", \"CB\", \"BD\", \"DB\", \"BE\", \"EB\", \"BF\", \"FB\")\n\npss_data <- pss %>%\n  filter(Procedure == \"Test\" & !(subject %in% excludedSubjects) & subject < 900)\n\npss_data$chooseAvoid <- NA\npss_data$chooseAvoid <- ifelse(pss_data$TrialType %in% chooseAtrials, \n                               \"chooseA\", pss_data$chooseAvoid)\npss_data$chooseAvoid <- ifelse(pss_data$TrialType %in% avoidBtrials, \n                               \"avoidB\", pss_data$chooseAvoid)\n\npssResults <- pss_data %>% \n  group_by(subject, chooseAvoid) %>%\n  summarise(accuracy = mean(as.numeric(StimulusPresentation2.ACC), na.rm=TRUE),\n            n_trials = n()) %>%\n  select(subject, chooseAvoid, accuracy) %>%\n  filter(!is.na(chooseAvoid)) %>%\n  spread(chooseAvoid, accuracy)\n\nkable(round(describe(pssResults[,2:3]), 2))\n\n```\n\n\n```{r pssDescription}\n#bootSummary(pssResults$avoidB)\n#bootSummary(pssResults$chooseA)\n#metaBootCor(pssResults$avoidB, pssResults$chooseA)\n\n```\n\n## Simon\n\n```{r simon, results='asis'}\nsimonResults <- simon %>%\n  filter(blockcode == \"testblock\" & !(subject %in% excludedSubjects) & subject < 900) %>%\n  select(subject, values.congruence, latency, correct) %>%\n  group_by(subject, values.congruence) %>%\n  summarize(mean_latency = mean(latency),\n            accuracy = asin(sqrt(mean(correct)))) %>%\n  unite(temp, mean_latency, accuracy, sep=\"W\", remove = TRUE)  %>%\n  spread(values.congruence, temp) %>%\n  separate(congruent, c(\"cong_latency\", \"cong_accuracy\"), sep=\"W\", convert=TRUE) %>%\n  separate(incongruent, c(\"inc_latency\", \"inc_accuracy\"), sep=\"W\", convert=TRUE) %>%\n  mutate(t_diff = as.numeric(inc_latency) - as.numeric(cong_latency))\n\n\nsimonBrief <- simon %>%\n  filter(blockcode == \"testblock\" & !(subject %in% excludedSubjects) & subject < 900) %>%\n  select(subject, values.congruence, latency, correct) %>%\n  group_by(subject, values.congruence) %>%\n  summarize(mean_latency = mean(latency)) %>%\n  spread(values.congruence, mean_latency) %>%\n  mutate(t_diff = as.numeric(incongruent) - as.numeric(congruent))\n\n```\n\n\n```{r}\npssSimon1 <- left_join(pssResults, simonBrief) %>%\n  select(subject, chooseA, avoidB, incongruent, congruent, t_diff)\n\npssSimon <- left_join(pssResults, simonResults) %>%\n  select(subject, chooseA, avoidB, inc_latency, cong_latency, inc_accuracy, cong_accuracy, t_diff)\n\n# cor.test(results$t_diff, results$chooseA)\n# cor.test(results$t_diff, results$avoidB)\n# cor.test(results$avoidB, as.numeric(results$incongruent))\n\n\n\nlibrary(corrplot)\ncormat <- cor(pssSimon, use = \"complete\")\n\ncorrplot(cormat)\n\n# ggplot(pssSimon, aes(x=avoidB, y=inc_latency)) +\n#   geom_point(shape=1) +    # Use hollow circles\n#   geom_smooth(method=lm) +\n#   geom_text(aes(label=paste(\"r=\", cor(pssSimon$avoidB, pssSimon$inc_latency, use=\"complete\"), sep=\"\")), x=1, y=-0.25)\n# \n# mmScatter <- function(xx, yy){\n#   val_cor <- cor(xx, yy, use = \"complete\")\n#   ggplot(aes(x=xx, y=yy)) +\n#     geom_point(shape=1) +    # Use hollow circles\n#     geom_smooth(method=lm) +\n#     geom_label(aes(x, y, label = lab), data= data.frame(xx, yy))\n# }\n# \n# \n# mmScatter(pssSimon$avoidB, pssSimon$inc_latency)\n```\n\n",
    "created" : 1488219007206.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1107041109",
    "id" : "D9B2C0EF",
    "lastKnownWriteTime" : 1488158387,
    "last_content_update" : 1488158387,
    "path" : "~/tabula/projects/ISIP/ISIP_analysis.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}